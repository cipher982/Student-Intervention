{
  "name": "Student-intervention",
  "tagline": "",
  "body": "\r\n# Project 2: Supervised Learning\r\n### Building a Student Intervention System\r\n\r\n## 2. Exploring the Data\r\n\r\nLet's go ahead and read in the student dataset first.\r\n\r\n_To execute a code cell, click inside it and press **Shift+Enter**._\r\n\r\n\r\n```python\r\n# Import libraries\r\nimport numpy as np\r\nimport pandas as pd\r\n```\r\n\r\n\r\n```python\r\n# Read student data\r\nstudent_data = pd.read_csv(\"student-data.csv\")\r\nprint \"Student data read successfully!\"\r\n# Note: The last column 'passed' is the target/label, all other are feature columns\r\n```\r\n\r\n    Student data read successfully!\r\n    \r\n\r\n\r\n```python\r\n# TODO: Compute desired values - replace each '?' with an appropriate expression/function call\r\nn_students = np.shape(student_data)[0]\r\nn_features = np.shape(student_data)[1] - 1 # Subtract target column\r\nn_passed = np.shape(student_data[student_data['passed']=='yes'])[0]\r\nn_failed = np.shape(student_data[student_data['passed']=='no'])[0]\r\ngrad_rate = float(n_passed) / float(n_students)*100\r\nprint \"Total number of students: {}\".format(n_students)\r\nprint \"Number of students who passed: {}\".format(n_passed)\r\nprint \"Number of students who failed: {}\".format(n_failed)\r\nprint \"Number of features: {}\".format(n_features)\r\nprint \"Graduation rate of the class: {:.2f}%\".format(grad_rate)\r\n```\r\n\r\n    Total number of students: 395\r\n    Number of students who passed: 265\r\n    Number of students who failed: 130\r\n    Number of features: 30\r\n    Graduation rate of the class: 67.09%\r\n    \r\n\r\n## 3. Preparing the Data\r\nIn this section, we will prepare the data for modeling, training and testing.\r\n\r\n### Identify feature and target columns\r\nIt is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\r\n\r\nLet's first separate our data into feature and target columns, and see if any features are non-numeric.<br/>\r\n**Note**: For this dataset, the last column (`'passed'`) is the target or label we are trying to predict.\r\n\r\n\r\n```python\r\n# Extract feature (X) and target (y) columns\r\nfeature_cols = list(student_data.columns[:-1])  # all columns but last are features\r\ntarget_col = student_data.columns[-1]  # last column is the target/label\r\nprint \"Feature column(s):-\\n{}\".format(feature_cols)\r\nprint \"Target column: {}\".format(target_col)\r\n\r\nX_all = student_data[feature_cols]  # feature values for all students\r\ny_all = student_data[target_col]  # corresponding targets/labels\r\nprint \"\\nFeature values:-\"\r\nprint X_all.head()  # print the first 5 rows\r\n```\r\n\r\n    Feature column(s):-\r\n    ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\r\n    Target column: passed\r\n    \r\n    Feature values:-\r\n      school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\r\n    0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \r\n    1     GP   F   17       U     GT3       T     1     1  at_home     other   \r\n    2     GP   F   15       U     LE3       T     1     1  at_home     other   \r\n    3     GP   F   15       U     GT3       T     4     2   health  services   \r\n    4     GP   F   16       U     GT3       T     3     3    other     other   \r\n    \r\n        ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\r\n    0   ...       yes       no        no       4         3     4    1    1      3   \r\n    1   ...       yes      yes        no       5         3     3    1    1      3   \r\n    2   ...       yes      yes        no       4         3     2    2    3      3   \r\n    3   ...       yes      yes       yes       3         2     2    1    1      5   \r\n    4   ...       yes       no        no       4         3     2    1    2      5   \r\n    \r\n      absences  \r\n    0        6  \r\n    1        4  \r\n    2       10  \r\n    3        2  \r\n    4        4  \r\n    \r\n    [5 rows x 30 columns]\r\n    \r\n\r\n### Preprocess feature columns\r\n\r\nAs you can see, there are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `internet`. These can be reasonably converted into `1`/`0` (binary) values.\r\n\r\nOther columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\r\n\r\nThese generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation.\r\n\r\n\r\n```python\r\n# Preprocess feature columns\r\ndef preprocess_features(X):\r\n    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\r\n\r\n    # Check each column\r\n    for col, col_data in X.iteritems():\r\n        # If data type is non-numeric, try to replace all yes/no values with 1/0\r\n        if col_data.dtype == object:\r\n            col_data = col_data.replace(['yes', 'no'], [1, 0])\r\n        # Note: This should change the data type for yes/no columns to int\r\n\r\n        # If still non-numeric, convert to one or more dummy variables\r\n        if col_data.dtype == object:\r\n            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\r\n\r\n        outX = outX.join(col_data)  # collect column(s) in output dataframe\r\n\r\n    return outX\r\n\r\nX_all = preprocess_features(X_all)\r\nprint \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns))\r\n```\r\n\r\n    Processed feature columns (48):-\r\n    ['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\r\n    \r\n\r\n### Split data into training and test sets\r\n\r\nSo far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding labels) into training and test sets.\r\n\r\n\r\n```python\r\nimport sklearn.cross_validation as cv\r\n\r\n\r\n# First, decide how many training vs test samples you want\r\nnum_all = student_data.shape[0]  # same as len(student_data)\r\nnum_train = 300  # about 75% of the data\r\nnum_test = num_all - num_train\r\nnum_ratio = float(num_train) / float(num_all)\r\n\r\n# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\r\n# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\r\n\r\nX_train, X_test, y_train, y_test = cv.train_test_split(X_all, y_all, test_size=(1 - num_ratio), random_state=1234)\r\n\r\n\r\n\r\nprint \"Training set: {} samples\".format(X_train.shape[0])\r\nprint \"Test set: {} samples\".format(X_test.shape[0])\r\n# Note: If you need a validation set, extract it from within training data\r\n```\r\n\r\n    Training set: 300 samples\r\n    Test set: 95 samples\r\n    \r\n\r\n## 4. Training and Evaluating Models\r\nChoose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem. For each model:\r\n\r\n- What are the general applications of this model? What are its strengths and weaknesses?\r\n- Given what you know about the data so far, why did you choose this model to apply?\r\n- Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant.\r\n\r\nProduce a table showing training time, prediction time, F<sub>1</sub> score on training set and F<sub>1</sub> score on test set, for each training set size.\r\n\r\nNote: You need to produce 3 such tables - one for each model.\r\n\r\n\r\n```python\r\n# Train a model\r\nimport time\r\n\r\n#timetotrain = []\r\ndef train_classifier(clf, X_train, y_train):\r\n    print \"Training {}...\".format(clf.__class__.__name__)\r\n    start = time.time()\r\n    clf.fit(X_train, y_train)\r\n    end = time.time()\r\n    print \"Done!\\nTraining time (secs): {:.3f}\".format(end - start)\r\n    #timetotrain.append(end - start)\r\n\r\n# TODO: Choose a model, import it and instantiate an object\r\nfrom sklearn.linear_model import LogisticRegression \r\n#from sklearn.neural_network import MLPClassifier\r\n#from sklearn.ensemble import RandomForestClassifier\r\nclf = LogisticRegression()\r\n\r\n# Fit model to training data\r\ntrain_classifier(clf, X_train, y_train)\r\n\r\n# note: using entire training set here\r\n#print clf  # you can inspect the learned model by printing it\r\n```\r\n\r\n    Training LogisticRegression...\r\n    Done!\r\n    Training time (secs): 0.005\r\n    \r\n\r\n\r\n```python\r\n# Predict on training set and compute F1 score\r\nfrom sklearn.metrics import f1_score\r\n\r\ndef predict_labels(clf, features, target):\r\n    print \"Predicting labels using {}...\".format(clf.__class__.__name__)\r\n    start = time.time()\r\n    y_pred = clf.predict(features)\r\n    end = time.time()\r\n    print \"Done!\\nPrediction time (secs): {:.3f}\".format(end - start)\r\n    return f1_score(target.values, y_pred, pos_label='yes')\r\n\r\ntrain_f1_score = predict_labels(clf, X_train, y_train)\r\nprint \"F1 score for training set: {}\".format(train_f1_score)\r\n```\r\n\r\n    Predicting labels using LogisticRegression...\r\n    Done!\r\n    Prediction time (secs): 0.001\r\n    F1 score for training set: 0.831050228311\r\n    \r\n\r\n\r\n```python\r\n# Predict on test data\r\nprint \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))\r\n```\r\n\r\n    Predicting labels using LogisticRegression...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for test set: 0.8\r\n    \r\n\r\n\r\n```python\r\n# Train and predict using different training set sizes\r\n\r\ndef train_predict(clf, X_train, y_train, X_test, y_test):\r\n    print \"------------------------------------------\"\r\n    print \"Training set size: {}\".format(len(X_train))\r\n    train_classifier(clf, X_train, y_train)\r\n    print \"F1 score for training set: {}\".format(predict_labels(clf, X_train, y_train))\r\n    print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))\r\n\r\n\r\n# TODO: Run the helper function above for desired subsets of training data\r\n# Note: Keep the test set constant\r\n\r\n# Sample slices the DF/Series and also randomizes\r\nX_train_100 = pd.DataFrame.sample(X_train, n = 100, random_state = 1234)\r\ny_train_100 =    pd.Series.sample(y_train, n = 100, random_state = 1234)\r\nX_train_200 = pd.DataFrame.sample(X_train, n = 200, random_state = 1234)\r\ny_train_200 =    pd.Series.sample(y_train, n = 200, random_state = 1234)\r\nX_train_300 = pd.DataFrame.sample(X_train, n = 300, random_state = 1234)\r\ny_train_300 =    pd.Series.sample(y_train, n = 300, random_state = 1234)\r\n\r\n\r\ntrain_predict(clf, X_train_100, y_train_100, X_test, y_test);\r\ntrain_predict(clf, X_train_200, y_train_200, X_test, y_test);\r\ntrain_predict(clf, X_train_300, y_train_300, X_test, y_test);\r\n```\r\n\r\n    ------------------------------------------\r\n    Training set size: 100\r\n    Training LogisticRegression...\r\n    Done!\r\n    Training time (secs): 0.003\r\n    Predicting labels using LogisticRegression...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for training set: 0.906832298137\r\n    Predicting labels using LogisticRegression...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for test set: 0.759124087591\r\n    ------------------------------------------\r\n    Training set size: 200\r\n    Training LogisticRegression...\r\n    Done!\r\n    Training time (secs): 0.003\r\n    Predicting labels using LogisticRegression...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for training set: 0.865979381443\r\n    Predicting labels using LogisticRegression...\r\n    Done!\r\n    Prediction time (secs): 0.001\r\n    F1 score for test set: 0.788321167883\r\n    ------------------------------------------\r\n    Training set size: 300\r\n    Training LogisticRegression...\r\n    Done!\r\n    Training time (secs): 0.005\r\n    Predicting labels using LogisticRegression...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for training set: 0.831050228311\r\n    Predicting labels using LogisticRegression...\r\n    Done!\r\n    Prediction time (secs): 0.001\r\n    F1 score for test set: 0.8\r\n    \r\n\r\n\r\n```python\r\n# While playing around with the training set size, I tried incredibly low numbers to see how they performed. \r\n# That's when I stumbled on the fact that a training size of 11 actually performed better than using a size of 300. \r\n# I'm not sure of the exact reasons behind this, but would be interested to learn why.\r\n\r\nX_train_11 = pd.DataFrame.sample(X_train, n = 11, random_state = 1234)\r\ny_train_11 =    pd.Series.sample(y_train, n = 11, random_state = 1234)\r\n\r\ntrain_predict(clf, X_train_11, y_train_11, X_test, y_test)\r\n```\r\n\r\n    ------------------------------------------\r\n    Training set size: 11\r\n    Training LogisticRegression...\r\n    Done!\r\n    Training time (secs): 0.001\r\n    Predicting labels using LogisticRegression...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for training set: 1.0\r\n    Predicting labels using LogisticRegression...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for test set: 0.805031446541\r\n    \r\n\r\n\r\n```python\r\n# TODO: Train and predict using two other models\r\n\r\n# Train and predict a basic decision tree classifier\r\nfrom sklearn import tree\r\nclf = tree.DecisionTreeClassifier()\r\ntrain_predict(clf, X_train_100, y_train_100, X_test, y_test)\r\ntrain_predict(clf, X_train_200, y_train_200, X_test, y_test)\r\ntrain_predict(clf, X_train_300, y_train_300, X_test, y_test)\r\n\r\n# Train and predict a gradient boosting classifier\r\nfrom sklearn.ensemble import GradientBoostingClassifier\r\nclf = GradientBoostingClassifier(n_estimators=100, learning_rate=.1, max_depth=3, random_state=1234).fit(X_train, y_train)\r\ntrain_predict(clf, X_train_100, y_train_100, X_test, y_test)\r\ntrain_predict(clf, X_train_200, y_train_200, X_test, y_test)\r\ntrain_predict(clf, X_train_300, y_train_300, X_test, y_test)\r\n\r\n\r\n```\r\n\r\n    ------------------------------------------\r\n    Training set size: 100\r\n    Training DecisionTreeClassifier...\r\n    Done!\r\n    Training time (secs): 0.010\r\n    Predicting labels using DecisionTreeClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.001\r\n    F1 score for training set: 1.0\r\n    Predicting labels using DecisionTreeClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for test set: 0.744186046512\r\n    ------------------------------------------\r\n    Training set size: 200\r\n    Training DecisionTreeClassifier...\r\n    Done!\r\n    Training time (secs): 0.002\r\n    Predicting labels using DecisionTreeClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for training set: 1.0\r\n    Predicting labels using DecisionTreeClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for test set: 0.709677419355\r\n    ------------------------------------------\r\n    Training set size: 300\r\n    Training DecisionTreeClassifier...\r\n    Done!\r\n    Training time (secs): 0.003\r\n    Predicting labels using DecisionTreeClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.001\r\n    F1 score for training set: 1.0\r\n    Predicting labels using DecisionTreeClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for test set: 0.650406504065\r\n    ------------------------------------------\r\n    Training set size: 100\r\n    Training GradientBoostingClassifier...\r\n    Done!\r\n    Training time (secs): 0.078\r\n    Predicting labels using GradientBoostingClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.003\r\n    F1 score for training set: 1.0\r\n    Predicting labels using GradientBoostingClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.001\r\n    F1 score for test set: 0.785185185185\r\n    ------------------------------------------\r\n    Training set size: 200\r\n    Training GradientBoostingClassifier...\r\n    Done!\r\n    Training time (secs): 0.109\r\n    Predicting labels using GradientBoostingClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.001\r\n    F1 score for training set: 0.992805755396\r\n    Predicting labels using GradientBoostingClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.001\r\n    F1 score for test set: 0.761194029851\r\n    ------------------------------------------\r\n    Training set size: 300\r\n    Training GradientBoostingClassifier...\r\n    Done!\r\n    Training time (secs): 0.136\r\n    Predicting labels using GradientBoostingClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.001\r\n    F1 score for training set: 0.97572815534\r\n    Predicting labels using GradientBoostingClassifier...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for test set: 0.820143884892\r\n    \r\n\r\n\r\n```python\r\n# Create the table / DataFrame - Logistic Regression\r\n\r\ncolumns = ['Training set size:','100','200','300']\r\ndata = np.array([['Training time (secs)',0.003,0.003,0.005], ['Prediction time (secs)',0.000,0.001,0.001],['F1 score for training set',0.90683,0.86598,0.83105],['F1 score for test set',0.75912,0.788321,0.8]])\r\n\r\nLogRegTable = pd.DataFrame(data, columns = columns)\r\n\r\n# Create the table / DataFrame - Decision Tree\r\n\r\ncolumns = ['Training set size:','100','200','300']\r\ndata2 = np.array([['Training time (secs)',0.010,0.002,0.003], ['Prediction time (secs)',0.000,0.000,0.000],['F1 score for training set',1.0,1.0,1.0],['F1 score for test set',0.74419,0.70967,0.650407]])\r\n\r\nDecTreeTable = pd.DataFrame(data2, columns = columns)\r\n\r\n# Create the table / DataFrame - Gradient Boosting\r\n\r\ncolumns = ['Training set size:','100','200','300']\r\ndata3 = np.array([['Training time (secs)',0.078,0.109,0.136], ['Prediction time (secs)',0.001,0.001,0.000],['F1 score for training set',1.0,0.99281,0.975728],['F1 score for test set',0.78519,0.761194,0.821439]])\r\n\r\nGradBoostTable = pd.DataFrame(data3, columns = columns)\r\n```\r\n\r\n\r\n```python\r\nLogRegTable\r\n```\r\n\r\n\r\n\r\n\r\n<div>\r\n<table border=\"1\" class=\"dataframe\">\r\n  <thead>\r\n    <tr style=\"text-align: right;\">\r\n      <th></th>\r\n      <th>Training set size:</th>\r\n      <th>100</th>\r\n      <th>200</th>\r\n      <th>300</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>0</th>\r\n      <td>Training time (secs)</td>\r\n      <td>0.003</td>\r\n      <td>0.003</td>\r\n      <td>0.005</td>\r\n    </tr>\r\n    <tr>\r\n      <th>1</th>\r\n      <td>Prediction time (secs)</td>\r\n      <td>0.0</td>\r\n      <td>0.001</td>\r\n      <td>0.001</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2</th>\r\n      <td>F1 score for training set</td>\r\n      <td>0.90683</td>\r\n      <td>0.86598</td>\r\n      <td>0.83105</td>\r\n    </tr>\r\n    <tr>\r\n      <th>3</th>\r\n      <td>F1 score for test set</td>\r\n      <td>0.75912</td>\r\n      <td>0.788321</td>\r\n      <td>0.8</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n</div>\r\n\r\n\r\n\r\n\r\n```python\r\nDecTreeTable\r\n```\r\n\r\n\r\n\r\n\r\n<div>\r\n<table border=\"1\" class=\"dataframe\">\r\n  <thead>\r\n    <tr style=\"text-align: right;\">\r\n      <th></th>\r\n      <th>Training set size:</th>\r\n      <th>100</th>\r\n      <th>200</th>\r\n      <th>300</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>0</th>\r\n      <td>Training time (secs)</td>\r\n      <td>0.01</td>\r\n      <td>0.002</td>\r\n      <td>0.003</td>\r\n    </tr>\r\n    <tr>\r\n      <th>1</th>\r\n      <td>Prediction time (secs)</td>\r\n      <td>0.0</td>\r\n      <td>0.0</td>\r\n      <td>0.0</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2</th>\r\n      <td>F1 score for training set</td>\r\n      <td>1.0</td>\r\n      <td>1.0</td>\r\n      <td>1.0</td>\r\n    </tr>\r\n    <tr>\r\n      <th>3</th>\r\n      <td>F1 score for test set</td>\r\n      <td>0.74419</td>\r\n      <td>0.70967</td>\r\n      <td>0.650407</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n</div>\r\n\r\n\r\n\r\n\r\n```python\r\nGradBoostTable\r\n```\r\n\r\n\r\n\r\n\r\n<div>\r\n<table border=\"1\" class=\"dataframe\">\r\n  <thead>\r\n    <tr style=\"text-align: right;\">\r\n      <th></th>\r\n      <th>Training set size:</th>\r\n      <th>100</th>\r\n      <th>200</th>\r\n      <th>300</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>0</th>\r\n      <td>Training time (secs)</td>\r\n      <td>0.078</td>\r\n      <td>0.109</td>\r\n      <td>0.136</td>\r\n    </tr>\r\n    <tr>\r\n      <th>1</th>\r\n      <td>Prediction time (secs)</td>\r\n      <td>0.001</td>\r\n      <td>0.001</td>\r\n      <td>0.0</td>\r\n    </tr>\r\n    <tr>\r\n      <th>2</th>\r\n      <td>F1 score for training set</td>\r\n      <td>1.0</td>\r\n      <td>0.99281</td>\r\n      <td>0.975728</td>\r\n    </tr>\r\n    <tr>\r\n      <th>3</th>\r\n      <td>F1 score for test set</td>\r\n      <td>0.78519</td>\r\n      <td>0.761194</td>\r\n      <td>0.821439</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n</div>\r\n\r\n\r\n\r\n\r\n```python\r\n# TODO: Fine-tune your model and report the best F1 score\r\nfrom sklearn import grid_search\r\nfrom sklearn.metrics import f1_score\r\nfrom sklearn.metrics import make_scorer\r\nf1_scorer = make_scorer(f1_score, pos_label=\"yes\")\r\n\r\n\r\n# Set the parameters to search, Logistic Regression is relatively simple, not many parameters\r\nmyparameters = {'C': [0.0001, 0.001, 0.01,0.05, 0.1,0.5, 1,5, 10, 100, 500,1000, 10000] }\r\nclf = grid_search.GridSearchCV(LogisticRegression(penalty='l2'), scoring = f1_scorer, param_grid = myparameters)\r\n\r\ntrain_predict(clf, X_train_300, y_train_300, X_test, y_test)\r\n\r\n```\r\n\r\n    ------------------------------------------\r\n    Training set size: 300\r\n    Training GridSearchCV...\r\n    Done!\r\n    Training time (secs): 0.356\r\n    Predicting labels using GridSearchCV...\r\n    Done!\r\n    Prediction time (secs): 0.000\r\n    F1 score for training set: 0.802395209581\r\n    Predicting labels using GridSearchCV...\r\n    Done!\r\n    Prediction time (secs): 0.001\r\n    F1 score for test set: 0.805031446541\r\n    \r\n\r\n### - What is the model's final F<sub>1</sub> score?\r\n\r\n#### Answer:\r\n\r\n  After tuning for possible parameter values, I am only able to obtain an 80.5% F<sub>1</sub> score. Which is just slightly higher than what the model was able to get before the grid search, at 80%.\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}